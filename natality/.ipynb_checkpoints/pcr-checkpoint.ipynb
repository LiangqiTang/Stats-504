{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Demographic predictors of birth counts in US counties from 2011-2020\n",
    "\n",
    "In this notebook we will explore predictors of natality, defined here as birth count per county/year, for a subset of US counties between 2011 and 2020.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad56373-f893-4ab1-9d5d-e673921b994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the birth count and other related data for analysis.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, gzip\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the data files\n",
    "pa = Path(\"/Users/liangqi/Library/Mobile Documents/com~apple~CloudDocs/Stats-504/natality/data\")\n",
    "\n",
    "# Create a long form version of the birth data.\n",
    "dl = []\n",
    "for y in range(2011, 2021):\n",
    "    bname = \"%4d.txt.gz\" % y\n",
    "    da = pd.read_csv(pa / bname, delimiter=\"\\t\",\n",
    "                     dtype={\"County Code\": object})\n",
    "    da = da[[\"County\", \"County Code\", \"Births\"]]\n",
    "    da[\"year\"] = y\n",
    "    dl.append(da)\n",
    "births = pd.concat(dl)\n",
    "births = births.rename({\"County Code\": \"FIPS\"}, axis=1)\n",
    "births[\"Births\"] = pd.to_numeric(births.Births, errors=\"coerce\")\n",
    "births = births.dropna()\n",
    "births = births[~births[\"County\"].str.contains(\"Unidentified\")]\n",
    "\n",
    "# Subset the demographics file to 2016.  This is a large file\n",
    "# and takes time, so only run this once and save the result\n",
    "# for future runs.\n",
    "if False:\n",
    "    f = pa / \"us.1990_2023.20ages.adjusted.txt.gz\"\n",
    "    g = pa / \"2016ages.txt.gz\"\n",
    "    with gzip.open(g, \"w\") as out:\n",
    "        with gzip.open(f) as inp:\n",
    "            for line in inp:\n",
    "                if line.startswith(b\"2016\"):\n",
    "                    out.write(line)\n",
    "\n",
    "# Read the demographics for 2016.  It is a fixed-width format\n",
    "# file.\n",
    "x = [1, 5, 7, 9, 12, 14, 15, 16, 17, 19, 27]\n",
    "cs = [(x[i]-1, x[i+1]-1) for i in range(len(x)-1)]\n",
    "with gzip.open(pa / \"2016ages.txt.gz\") as io:\n",
    "    demog = pd.read_fwf(io, colspecs=cs, header=None)\n",
    "demog.columns = [\"Year\", \"State\", \"StateFIPS\", \"CountyFIPS\", \"Registry\",\n",
    "                 \"Race\", \"Origin\", \"Sex\", \"Age\", \"Population\"]\n",
    "\n",
    "# Create a FIPS code that matches the FIPS code in the birth data\n",
    "demog[\"FIPS\"] = [\"%02d%03d\" % (x, y) for (x, y) in zip(demog.StateFIPS, demog.CountyFIPS)]\n",
    "demog = demog[[\"FIPS\", \"Race\", \"Origin\", \"Sex\", \"Age\", \"Population\"]]\n",
    "\n",
    "# Recode some variables to more interpretable text labels\n",
    "# See http://seer.cancer.gov/popdata/popdic.html for code information\n",
    "demog[\"Sex\"] = demog[\"Sex\"].replace([2, 1], [\"F\", \"M\"]) # Female/Male\n",
    "demog[\"Origin\"] = demog[\"Origin\"].replace([0, 1], [\"N\", \"H\"]) # Non-Hispanic/Hispanic\n",
    "demog[\"Race\"] = demog[\"Race\"].replace([1, 2, 3, 4], [\"W\", \"B\", \"N\", \"A\"]) # White/Black/Native/Asian\n",
    "\n",
    "# The overall population per county\n",
    "pop = demog.groupby(\"FIPS\")[\"Population\"].sum().reset_index()\n",
    "\n",
    "# Pivot to put the age bands in the columns\n",
    "demog = demog.pivot(index=\"FIPS\", columns=[\"Race\", \"Origin\", \"Sex\", \"Age\"], values=\"Population\")\n",
    "\n",
    "# Age group labels\n",
    "age_groups = [\"0\", \"1-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\", \"30-34\", \"35-39\",\n",
    "              \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\",\n",
    "              \"80-84\", \"85-89\", \"90+\"]\n",
    "\n",
    "na = demog.columns.tolist()\n",
    "demog.columns = [\"%s_%s_%s_%d\" % tuple(x) for x in na]\n",
    "\n",
    "# Replace missing demographic values with 0.\n",
    "demog = demog.fillna(0)\n",
    "\n",
    "# Get the Rural/Urban Continuity Codes (RUCC)\n",
    "rucc = pd.read_excel(pa / \"ruralurbancodes2013.xls\", sheet_name=None)\n",
    "rucc = rucc[\"Rural-urban Continuum Code 2013\"]\n",
    "rucc = rucc[[\"FIPS\", \"RUCC_2013\"]]\n",
    "rucc[\"FIPS\"] = [\"%05d\" % x for x in rucc.FIPS]\n",
    "\n",
    "# Get the ADI values, need to aggregate from zip code to county code\n",
    "fname = \"US_2022_ADI_Census_Block_Group_v4_0_1.csv.gz\"\n",
    "dt = {\"FIPS\": str, \"ADI_NATRANK\": str}\n",
    "adi = pd.read_csv(pa / fname, usecols=[\"FIPS\", \"ADI_NATRANK\"], dtype=dt)\n",
    "adi[\"ADI_NATRANK\"] = pd.to_numeric(adi[\"ADI_NATRANK\"], errors=\"coerce\")\n",
    "adi[\"FIPS5\"] = [x[0:5] for x in adi[\"FIPS\"]]\n",
    "adi = adi.groupby(\"FIPS5\")[\"ADI_NATRANK\"].agg(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kshedden/data/Teaching/natality/2011.txt.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m births, demog, pop, na, age_groups, rucc, adi\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Stats-504/natality/prep.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2011\u001b[39m, \u001b[38;5;241m2021\u001b[39m):\n\u001b[1;32m     14\u001b[0m     bname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%4d\u001b[39;00m\u001b[38;5;124m.txt.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y\n\u001b[0;32m---> 15\u001b[0m     da \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCounty Code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     da \u001b[38;5;241m=\u001b[39m da[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCounty\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCounty Code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBirths\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     18\u001b[0m     da[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTc/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTc/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTc/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTc/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTc/lib/python3.11/site-packages/pandas/io/common.py:765\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    764\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[1;32m    772\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[1;32m    773\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[1;32m    777\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTc/lib/python3.11/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, mode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kshedden/data/Teaching/natality/2011.txt.gz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prep import births, demog, pop, na, age_groups, rucc, adi\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "View some of the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "births.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rucc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Create a dataframe for modeling.  Merge the birth data with population and RUCC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.merge(births, pop, on=\"FIPS\", how=\"left\")\n",
    "da = pd.merge(da, rucc, on=\"FIPS\", how=\"left\")\n",
    "da = pd.merge(da, adi, left_on=\"FIPS\", right_on=\"FIPS5\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Population will be used as an offset below, so we log it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"logPop\"] = np.log(da[\"Population\"])\n",
    "da[\"logADINatRank\"] = np.log(1 + da[\"ADI_NATRANK\"])\n",
    "da = da.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "It's not always essential to center quantitative variables, but it makes it easier to interpret their effects, especially when interactions are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"yearc\"] = da[\"year\"] - da[\"year\"].mean()\n",
    "da[\"logPopc\"] = da[\"logPop\"] - da[\"logPop\"].mean()\n",
    "da[\"RUCC_2013c\"] = da[\"RUCC_2013\"] - da[\"RUCC_2013\"].mean()\n",
    "da[\"logADINatRank\"] = da[\"logADINatRank\"] - da[\"logADINatRank\"].mean()\n",
    "da[\"logADINatRankZ\"] = da[\"logADINatRank\"] / da[\"logADINatRank\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "One point that we will focus on below is the extent to which urbanicity (RUCC) and/or adversity (ADI) predict natality (after controlling for population size).  RUCC and ADI are related, but this does not mean that we cannot attempt to disentangle their roles in the regression.  The plot below giv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = da[[\"RUCC_2013c\", \"logADINatRankZ\"]]\n",
    "lm = lowess(px[\"logADINatRankZ\"], px[\"RUCC_2013c\"])\n",
    "plt.plot(px[\"RUCC_2013c\"], px[\"logADINatRankZ\"], \"o\")\n",
    "plt.xlabel(\"RUCC\")\n",
    "plt.ylabel(\"ADI (Z-score)\")\n",
    "plt.plot(lm[:, 0], lm[:, 1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Scaling by population size and offsets\n",
    "\n",
    "It is natural to expect a 1-1 scaling between total population size and the number of births.  That is, all else equal we would expect two counties that differ by a factor of two in population size to differ by two in natality.  To assess this, we can make a scatterplot of the birth count versus the population size in log-space.  Under the expected 1-1 scaling, the slope of this line should be close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.sort_values([\"FIPS\", \"year\"])\n",
    "da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"logBirths\"] = np.log(da[\"Births\"])\n",
    "sns.scatterplot(da, x=\"logPop\", y=\"logBirths\", alpha=0.3)\n",
    "plt.grid(True)\n",
    "b = np.cov(da[\"logPop\"], da[\"logBirths\"])[0, 1] / np.var(da[\"logPop\"])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Assessing the variance structure and mean/variance relationships\n",
    "\n",
    "Since we have 10 years of data for each county, we can treat these as replicates to estimate the mean and variance within each county (over the 10 years covered by the dataset).  This is one way for us to assess the mean/variance relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = births.groupby(\"FIPS\")[\"Births\"].agg([np.mean, np.var])\n",
    "lmv = np.log(mv)\n",
    "mv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Regress log variance on log mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = sm.OLS.from_formula(\"var ~ mean\", lmv).fit()\n",
    "print(mr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Plot the log variance against the log mean.  If variance = phi * mean, then log(variance) = log(phi) + log(mean), i.e. the slope is 1 and the intercept is log(phi).  If variance = phi * mean^a then log(variance) = log(phi) + a * log(mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.plot(lmv[\"mean\"], lmv[\"var\"], \"o\", alpha=0.2, rasterized=True)\n",
    "plt.axline((8, 8), slope=1, color=\"grey\")\n",
    "plt.axline((lmv[\"mean\"].mean(0), lmv[\"var\"].mean(0)), slope=1, color=\"purple\")\n",
    "plt.axline((8, mr.params[0]+8*mr.params[1]), slope=mr.params[1], color=\"orange\")\n",
    "plt.xlabel(\"Log mean\", size=16)\n",
    "plt.ylabel(\"Log variance\", size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Urbanicity and time trends as predictors of natality\n",
    "\n",
    "Below we fit a GLM, which is not appropriate since we have repeated measures on counties.  Due to the repeated measures, the uncertainty assessments (standard errors, p-values, confidence intervals, score tests) will be invalid, but the point estimates of the coefficients are still meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fml = \"Births ~ logPop + RUCC_2013 + logADINatRankZ\"\n",
    "m0 = sm.GLM.from_formula(fml, family=sm.families.Poisson(), data=da)\n",
    "r0 = m0.fit() # Poisson\n",
    "r0x = m0.fit(scale=\"X2\") # Quasi-Poisson\n",
    "r0x.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Using GEE accounts for the correlated data.  After accounting for clustering by county, ADI remains significant but RUCC looses significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = sm.GEE.from_formula(fml, groups=\"FIPS\", family=sm.families.Poisson(), data=da)\n",
    "r1 = m1.fit() # Poisson and quasi-Poisson are the same for GEE\n",
    "r1x = m1.fit(scale=\"X2\")\n",
    "r1x.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Use log population as an offset instead of a covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = sm.GEE.from_formula(\"Births ~ RUCC_2013 + logADINatRankZ\", groups=\"FIPS\", offset=\"logPop\",\n",
    "                         family=sm.families.Poisson(), data=da)\n",
    "r2 = m2.fit(scale=\"X2\")\n",
    "r2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Below we construct a diagnostic plot for the variance structure that does not require there to be replicates  (in general there will be no replicates, and even here it is unclear whether we can treat the 10 years of data within each county as replicates).  If the variance structure is correctly specified, then the absolute Pearson residuals should have constant conditional mean with respect to the fitted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "lfv = np.log(r2.fittedvalues).values\n",
    "apr = np.abs(r2.resid_pearson)\n",
    "ii = np.argsort(lfv)\n",
    "lfv = lfv[ii]\n",
    "apr = apr[ii]\n",
    "ff = sm.nonparametric.lowess(apr, lfv)\n",
    "plt.plot(lfv, apr, \"o\", alpha=0.2, rasterized=True)\n",
    "plt.plot(ff[:, 0], ff[:, 1], \"-\", color=\"orange\")\n",
    "plt.title(\"Poisson mean/variance model\")\n",
    "plt.xlabel(\"Log predicted mean\", size=16)\n",
    "plt.ylabel(\"Absolute Pearson residual\", size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "The Poisson variance model did not fit well based on the diagnostic plot above, so we next consider a Gamma family to better match the mean/variance relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = sm.GEE.from_formula(\"Births ~ RUCC_2013\", groups=\"FIPS\", offset=\"logPop\",\n",
    "                         family=sm.families.Gamma(link=sm.families.links.log()), data=da)\n",
    "r3 = m3.fit(scale=\"X2\")\n",
    "r3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Diagnostic plot for mean/variance relationship with gamma model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "lfv = np.log(r3.fittedvalues).values\n",
    "apr = np.abs(r3.resid_pearson)\n",
    "ii = np.argsort(lfv)\n",
    "lfv = lfv[ii]\n",
    "apr = apr[ii]\n",
    "ff = sm.nonparametric.lowess(apr, lfv)\n",
    "plt.plot(lfv, apr, \"o\", alpha=0.2, rasterized=True)\n",
    "plt.plot(ff[:, 0], ff[:, 1], \"-\", color=\"orange\")\n",
    "plt.title(\"Gamma mean/variance model\")\n",
    "plt.xlabel(\"Log predicted mean\", size=16)\n",
    "plt.ylabel(\"Absolute Pearson residual\", size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Now we proceed to fit and interpret some regression models.  Here we use exchangeable correlation structure in the GEE.  Since RUCC and ADI are constant within groups, the parameter estimates and standard errors are the same as with the independence model.  The first model only considers the roles of urbanicity (RUCC) and deprivation (ADI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = sm.GEE.from_formula(\"Births ~ RUCC_2013 + logADINatRankZ\", groups=\"FIPS\", offset=\"logPop\",\n",
    "                         cov_struct=sm.cov_struct.Exchangeable(),\n",
    "                         family=sm.families.Gamma(link=sm.families.links.log()), data=da)\n",
    "r4 = m4.fit(scale=\"X2\")\n",
    "r4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Now we consider the role of urbanicity as well as the potential for a linear time trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = sm.GEE.from_formula(\"Births ~ RUCC_2013 + logADINatRankZ + year\", groups=\"FIPS\", offset=\"logPop\",\n",
    "                         cov_struct=sm.cov_struct.Exchangeable(),\n",
    "                         family=sm.families.Gamma(link=sm.families.links.log()), data=da)\n",
    "r5 = m5.fit(scale=\"X2\")\n",
    "r5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Now we consider the possibility that the linear time trend is different based on the level of deprivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6 = sm.GEE.from_formula(\"Births ~ (logADINatRankZ + RUCC_2013c) * yearc\", groups=\"FIPS\", offset=\"logPop\",\n",
    "                         cov_struct=sm.cov_struct.Exchangeable(),\n",
    "                         family=sm.families.Gamma(link=sm.families.links.log()), data=da)\n",
    "r6 = m6.fit(scale=\"X2\")\n",
    "r6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Score tests comparing pairs of nested models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r5.model.compare_score_test(r4))\n",
    "print(r6.model.compare_score_test(r5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Principal Components Regression\n",
    "\n",
    "We begin by double centering the demographic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "demogx = np.asarray(demog)\n",
    "demogx = np.log(1 + demogx)\n",
    "demogx -= demogx.mean()\n",
    "demogx -= demogx.mean(0)\n",
    "demogx -= demogx.mean(1)[:, None]\n",
    "demog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Get factors (principal components) from the demographic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = np.linalg.svd(demogx, 0)\n",
    "v = vt.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Convert the coefficients back to the original coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_coef(c, npc):\n",
    "    return np.dot(v[:, 0:npc], c/s[0:npc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Put the demographic factors into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {(\"pc%02d\" % k) : u[:, k] for k in range(100)}\n",
    "m[\"FIPS\"] = demog.index\n",
    "demog_f = pd.DataFrame(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Merge demographic information into the births data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.merge(da, demog_f, on=\"FIPS\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Include this number of factors in subsequent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "npc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "A GLM, not appropriate since we have repeated measures on counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fml = \"Births ~ (logPopc + RUCC_2013c) * yearc + \" + \" + \".join([\"pc%02d\" % j for j in range(npc)])\n",
    "m7 = sm.GLM.from_formula(fml, family=sm.families.Poisson(), data=da)\n",
    "r7 = m7.fit(scale=\"X2\")\n",
    "r7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "GEE accounts for the correlated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "m8 = sm.GEE.from_formula(fml, groups=\"FIPS\",\n",
    "         family=sm.families.Gamma(link=sm.families.links.log()), data=da)\n",
    "r8 = m8.fit(scale=\"X2\")\n",
    "r8.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Use log population as an offset instead of a covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fml = \"Births ~ \" + \" + \".join([\"pc%02d\" % j for j in range(npc)])\n",
    "m9 = sm.GEE.from_formula(fml, groups=\"FIPS\", offset=\"logPop\",\n",
    "         family=sm.families.Gamma(link=sm.families.links.log()), data=da)\n",
    "r9 = m9.fit(scale=\"X2\")\n",
    "r9.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Restructure the coefficients so that the age bands are in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def restructure(c):\n",
    "    ii = pd.MultiIndex.from_tuples(na)\n",
    "    c = pd.Series(c, index=ii)\n",
    "    c = c.unstack()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "This function fits a Gamma GLM to the data using 'npc' principal components as explanatory variables (using GEE to account for non-independence), then converts the coefficients back to the original variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fitmodel(npc):\n",
    "    # A GEE using log population as an offset\n",
    "    fml = \"Births ~ 1\" if npc == 0 else \"Births ~ RUCC_2013c*yearc + \" + \" + \".join([\"pc%02d\" % j for j in range(npc)])\n",
    "    m = sm.GEE.from_formula(fml, groups=\"FIPS\", family=sm.families.Gamma(link=sm.families.links.log()),\n",
    "                            offset=da[\"logPop\"], data=da)\n",
    "    r = m.fit(scale=\"X2\")\n",
    "\n",
    "    # Convert the coefficients back to the original coordinates\n",
    "    c = convert_coef(r.params[4:], npc)\n",
    "\n",
    "    # Restructure the coefficients so that the age bands are\n",
    "    # in the columns.\n",
    "    c = restructure(c)\n",
    "\n",
    "    return c, m, r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Plot styling information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"A\": \"purple\", \"B\": \"orange\", \"N\": \"lime\", \"W\": \"red\"}\n",
    "lt = {\"F\": \"-\", \"M\": \":\"}\n",
    "sym = {\"H\": \"s\", \"N\": \"o\"}\n",
    "ages = range(0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Fit models with these numbers of PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for npc in pcs:\n",
    "\n",
    "    c, m, r = fitmodel(npc)\n",
    "    models.append((m, r))\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    ax = plt.axes([0.14, 0.18, 0.7, 0.75])\n",
    "    ax.grid(True)\n",
    "    for i in range(c.shape[0]):\n",
    "        a = c.index[i]\n",
    "        la = \"/\".join(a)\n",
    "        ax.plot(ages, c.iloc[i, :], lt[a[2]] + sym[a[1]], color=colors[a[0]],\n",
    "                label=la)\n",
    "\n",
    "    # Setup the horizontal axis labels\n",
    "    ax.set_xticks(ages)\n",
    "    ax.set_xticklabels(age_groups)\n",
    "    for x in plt.gca().get_xticklabels():\n",
    "        x.set_rotation(-90)\n",
    "\n",
    "    ha, lb = plt.gca().get_legend_handles_labels()\n",
    "    leg = plt.figlegend(ha, lb, loc=\"center right\")\n",
    "    leg.draw_frame(False)\n",
    "\n",
    "    plt.xlabel(\"Age group\", size=17)\n",
    "    plt.ylabel(\"Coefficient\", size=17)\n",
    "    plt.title(\"%d factors\" % npc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Use score tests to get a sense of the number of PC factors to include; also consider the PVEs calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    st = models[k+1][0].compare_score_test(models[k][1])\n",
    "    print(\"%d versus %d: p=%f\" % (pcs[k+1], pcs[k], st[\"p-value\"]))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
