# iNaturalist

iNaturalist is a platform that records observations of living organisms, annotated with their locations and taxonomic identifications. We will be considering data from two classes of plants in this notebook. Our goal here is to illustrate the concept of "large scale inference", to study the presence of systematic changes in species locations over time.

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(locfdr)
library(roll)
library(ggplot2)
```

Select a class of plants to analyze.

```{r}
#pclass = "Pinopsida"
pclass = "Polypodiopsida"

pa = sprintf("/home/kshedden/data/Teaching/inaturalist/Plantae_%s.csv.gz", pclass)
```

Below we load the data and construct a time variable that starts on January 1, 2015 and counts in 1000's of days from that origin. In the analysis conducted below, we will be interested in the evidence that for each specific species, the average latitude changes linearly as a function of this 'day' variable.

```{r}
da = read_csv(pa)
da = da %>% mutate(eventDate = as.Date(eventDate))
da = da %>% filter(eventDate >= as.Date('2015-01-01'))
da = da %>% select(!elevation) %>% drop_na()
da = da %>% mutate(date1 = as.Date('2015-01-01'))
da = da %>% mutate(day=difftime(eventDate, date1, units="days")/1000)
```

This histogram below shows that the number of occurrences of individuals in a species has a very skewed distribution.

```{r}
dn = da %>% group_by(species) %>% summarize(n=n())
dn = dn %>% mutate(logn=log10(n))
plt = ggplot(dn, aes(x=logn)) + geom_histogram()
print(plt)
```

Below we calculate the mean latitude for each species.  Individual plants within each species occur at various locations, but each species has a geographic centroid.  We compute the centroid for latitude below since that is our focus here.

```{r}
dm = da %>% group_by(species) %>% summarize(species_latitude=mean(decimalLatitude))
da = inner_join(da, dm, by="species")
head(da)
```
Below we calculate the intraclass correlation coefficient (ICC) of the latitude values, which describes the extent to which different species cluster by latitude.  An ICC of 1 corresponds to complete clustering and an ICC of 0 corresponds to no clustering.

```{r}
var(da$species_latitude) / var(da$decimalLatitude)
```

When we fit regression models below, we will analyze longitude as a circular variable.

```{r}
da = da %>% mutate(lonrad=pi*decimalLongitude/180)
da = da %>% mutate(lonrad_sin=sin(lonrad), lonrad_cos=cos(lonrad))
```

Using circular statistics, calculate the longitudinal center for each species.

```{r}
da = da %>% group_by(species) %>% transform(lonrad_sin_cen=mean(lonrad_sin), lonrad_cos_cen=mean(lonrad_cos))
u = sqrt(da$lonrad_sin_cen^2 + da$lonrad_cos_cen^2)
da$lonrad_sin_cen = da$lonrad_sin_cen / u
da$lonrad_cos_cen = da$lonrad_cos_cen / u
```

Now calculate residuals of the longitude relative to the center

```{r}
da = da %>% mutate(lonrad_cos_resid=lonrad_cos-lonrad_cos_cen, lonrad_sin_resid=lonrad_sin-lonrad_sin_cen)
```

Below we create a synthetic variable that cannot contain any new information about plant locations.  It will be used below as a negative control to evaluate the performance of large scale inference procedures.

```{r}
da = da %>% mutate(fake=lonrad_cos+rnorm(length(lonrad_cos)))
```

Below we fit a linear model for each species that predicts latitude from the time variable called "day" (the number of days, in thousands, since the time origin) and some other control variables. The main interest here is the relationship between "day" and the conditional mean latitude of a species. If the slope of day on latitude is positive for a given species, this species is identified at more northerly locations as time progresses. If the coefficient is negative the species is identified at more southerly locations as time progresses. We assess these effects using two models. The first model has only main effects and the second model allows the time trend in mean latitude to vary by longitude.

```{r}
f = function(x, y) {
  species = as.character(y)
  if (nrow(x) < 10) {
    return(list(species=species, n=nrow(x)))
  }
  
  m1 = lm(decimalLatitude ~ day + lonrad_sin + lonrad_cos + fake, data=x)
  m2 = lm(decimalLatitude ~ day * (lonrad_sin + lonrad_cos + fake), data=x)

  lrt = anova(m1, m2)
  
  stat = lrt$F[[2]]
  dof = lrt$Df[[2]]
  
  lrt_z = qnorm(pchisq(stat, dof))
  
  if (dof == 3) {
    # The log likelihood ratio statistics is chi^2 under the null.  We use the 
    # Wilson and Hilferty transformation to transform it from chi-square to Gaussian.
    lrt_zwh = (stat / dof)^(1/3) - (1 - 2/(9*dof))
    lrt_zwh = lrt_zwh / sqrt(2/(9*dof))
  } else {
    lrt_zwh = NA
  }
  
  s = sqrt(diag(vcov(m1)))
  day_slope = coef(m1)[["day"]]
  day_slope_se = s[["day"]]
  fake_slope = coef(m1)[["fake"]]
  fake_slope_se = s[["fake"]]

  return(list(species=species, n=nrow(x), lrt_z=lrt_z, lrt_zwh=lrt_zwh,
              day_slope=day_slope, day_slope_se=day_slope_se,
              fake_slope=fake_slope, fake_slope_se=fake_slope_se))
}

rr = da %>% group_by(species) %>% group_map(f) %>% bind_rows()
```

The following plot shows that the cube root (Wilson Hilferty) and "exact" Z-scores are very similar.

```{r}
plt = ggplot(rr, aes(x=lrt_z, y=lrt_zwh)) + geom_point() + xlim(-5, 5) + ylim(-5, 5)
print(plt)
```

Below we construct T-scores for parameters of interest. For species with large sample sizes these T-scores should also be approximate Z-scores (they approximately follow a standard normal distribution under the null hypothesis that the day slope is zero). For smaller sample sizes we need to account for the uncertainty in the scale parameter estimate induced by the limited degrees of freedom.

```{r}
rr = rr %>% mutate(day_slope_t=day_slope/day_slope_se, fake_slope_t=fake_slope/fake_slope_se)
```

```{r}
rr = left_join(rr, dm, by="species")
```

Account for finite group sizes, by mapping the t-distributed statistics to normally distributed statistics.

```{r}
rr = rr %>% mutate(day_slope_z=qnorm(pt(day_slope_t, n-5)))
rr = rr %>% mutate(fake_slope_z=qnorm(pt(fake_slope_t, n-5)))
```

Plot the z-scores against the t-scores to see the effect of the transformation.

```{r}
plt = ggplot(rr, aes(x=day_slope_t, y=day_slope_z)) + geom_point()
print(plt)
```
Below we construct QQ plots for the z-scores for day, the fake (synthetic) variable, and the transformed log-likelihood ratio test statistic.

```{r}
for (vn in c("day_slope_z", "fake_slope_z", "lrt_z")) {
  plt = ggplot(rr, aes(sample=.data[[vn]])) + stat_qq(na.rm=T)
  plt = plt + geom_abline(intercept=0, slope=1) + ylim(-1, 4)
  print(plt)
}
```
Since many species have a strong interaction between longitude and day, we reconstruct the data using
an interaction model that controls for deviations from the mean species longitude.

```{r}
f = function(x, y) {
  species = as.character(y)
  if (nrow(x) < 10) {
    return(list(species=species, n=nrow(x)))
  }
  
  m1 = lm(decimalLatitude ~ day * (lonrad_sin_resid + lonrad_cos_resid + fake), data=x)

  s = sqrt(diag(vcov(m1)))
  day_slope = coef(m1)[["day"]]
  day_slope_se = s[["day"]]
  fake_slope = coef(m1)[["fake"]]
  fake_slope_se = s[["fake"]]

  return(list(species=species, n=nrow(x), 
              day_slope=day_slope, day_slope_se=day_slope_se,
              fake_slope=fake_slope, fake_slope_se=fake_slope_se))
}

rr = da %>% group_by(species) %>% group_map(f) %>% bind_rows()
rr = rr %>% mutate(day_slope_t=day_slope/day_slope_se, fake_slope_t=fake_slope/fake_slope_se)
rr = left_join(rr, dm, by="species")
rr = rr %>% mutate(day_slope_z=qnorm(pt(day_slope_t, n-5)))
rr = rr %>% mutate(fake_slope_z=qnorm(pt(fake_slope_t, n-5)))
```

The value calculated below is the threshold needed to control the family-wise error rate (FWER) at 0.05.

```{r}
n = length(is.finite(rr$day_slope_z))
bonf_z = qnorm(1 - 0.025/n)
bonf_z
```

Below we calculate the local FDR for the day slope estimates.

```{r}
zz = rr$day_slope_z
ii = is.finite(zz)
zz = zz[ii]
lfdr = locfdr(zz, nulltype=0)
rr$locfdr = NA
rr$locfdr[ii] = lfdr$fdr
```

Below we count the number of species with local FDR smaller than 0.1.

```{r}
sum(lfdr$fdr < 0.1)
```

Below we have a plot that shows the cumulative number of species with FDR below each threshold.

```{r}
n = nrow(rr)
rr = rr %>% arrange(locfdr)
plt = ggplot(rr, aes(x=seq(n), y=locfdr)) + geom_line()
plt = plt + xlim(1, 600)
print(plt)
```
Next we assess whether the species with the greatest evidence for range changes tend to fall at specific latitude values.

```{r}
rr1 = rr %>% select(species_latitude, day_slope_z) %>% drop_na() %>% arrange(species_latitude)
rr1$y1 = roll_quantile(rr1$day_slope_z, width=150, p=0.1)
rr1$y2 = roll_quantile(rr1$day_slope_z, width=150, p=0.9)
rr1$z1 = qnorm(0.1)
rr1$z2 = qnorm(0.9)

plt = ggplot(rr1, aes(x=species_latitude, y=day_slope_z)) + geom_point() 
plt = plt + geom_line(aes(x=species_latitude, y=y1, color="orange"))
plt = plt + geom_line(aes(x=species_latitude, y=y2, color="orange"))
plt = plt + geom_line(aes(x=species_latitude, y=z1, color="purple"))
plt = plt + geom_line(aes(x=species_latitude, y=z2, color="purple"))
plt = plt + theme(legend.position="none")
print(plt)
```

Next we plot the day slope Z-score against the sample size. If we are mainly limited by power then the larger Z-scores will be concentrated where the sample size is larger. This plot makes it clear that there are some Z-scores falling far outside the likely range for a standard normal variable, and these values can be either positive or negative. Most of the largest Z-scores (in magnitude) occur with the larger sample sizes.

```{r}
rr1 = rr %>% select(n, day_slope_z) %>% drop_na() %>% arrange(n)
rr1 = rr1 %>% mutate(logn = log(n))
rr1$y1 = roll_quantile(rr1$day_slope_z, width=150, p=0.1)
rr1$y2 = roll_quantile(rr1$day_slope_z, width=150, p=0.9)
rr1$z1 = qnorm(0.1)
rr1$z2 = qnorm(0.9)

plt = ggplot(rr1, aes(x=logn, y=day_slope_z)) + geom_point()
plt = plt + geom_line(aes(x=logn, y=y1, color="orange"))
plt = plt + geom_line(aes(x=logn, y=y2, color="orange"))
plt = plt + geom_line(aes(x=logn, y=z1, color="purple"))
plt = plt + geom_line(aes(x=logn, y=z2, color="purple"))
plt = plt + theme(legend.position="none")
print(plt)
```
Another way to assess whether the Z-scores with greater magnitude concentrate in the species with larger sample sizes is to smooth the absolute Z-score against the log sample size as below.  Doing this, we loose the ability to distinguish positive from negative Z-scores, but we do see a clear tendency for the largest Z-scores to occur in the species with the greatest number of observations.

```{r}
plt = ggplot(rr1, aes(x=logn, y=abs(day_slope_z))) + geom_smooth()
plt = plt + geom_hline(yintercept=sqrt(2/pi))
plt = plt + scale_y_continuous(expand = c(0, 0), limits = c(0, NA))
print(plt)
```
