{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Understanding predictors of blood pressure in US adults using kernel ridge regression\n",
    "\n",
    "Kernel ridge regression (KRR) is a nonparametric regression technique.  KRR has the potential to identify non-additive and non-linear conditional mean structures automatically, without needing to specify a regression formula or test a large set of models to identify the one that fits best.  To use KRR we specify a positive semidefinite kernel function, and a regularization parameter $\\lambda \\ge 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from read import df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We will use KRR to explain the variation in SBP in terms of the covariates in 'vx' below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = [\"RIAGENDR\", \"RIDAGEYR\", \"BMXWT\", \"BMXHT\", \"BMXBMI\", \"BMXLEG\",\n",
    "      \"BMXARML\", \"BMXARMC\", \"BMXWAIST\", \"BMXHIP\"]\n",
    "vn = [\"BPXSY1\"] + vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df.loc[:, vn].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Recode everything as numeric, convert to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx[\"RIAGENDRx\"] = dx.RIAGENDR.replace({\"F\": 1, \"M\": -1})\n",
    "vxx = [\"RIAGENDRx\" if x == \"RIAGENDR\" else x for x in vx]\n",
    "X = dx[vxx].values\n",
    "y = dx[\"BPXSY1\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Standardize all variables (this is not essential but makes the results easier to interpret, and makes the algorithm easier to train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmn = X.mean(0)\n",
    "X -= xmn\n",
    "xsd = X.std(0)\n",
    "X /= xsd\n",
    "ymn = y.mean()\n",
    "y -= ymn\n",
    "ysd = y.std()\n",
    "y /= ysd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Fit a linear model using OLS for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "u, s, vt = np.linalg.svd(X, 0)\n",
    "yh = np.dot(u, np.dot(u.T, y))\n",
    "rmse_ols = np.sqrt(np.mean((y - yh)**2))\n",
    "rmse_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "A key component of kernel ridge regression is a kernel function, that is used to measure the similarity between two observations based on their covariate vectors.  Two of the most common kernels are the squared exponential kernel (a radial basis kernel), and the polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ker_sqexp(X, scale, Y=None):\n",
    "    \"\"\"Squared exponential kernel with a given scale parameter.\"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    D = cdist(X, Y)\n",
    "    return np.exp(-D**2 / (2*scale**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ker_poly(X, c=1, p=2, Y=None):\n",
    "    \"\"\"Polynomial kernel with given interept and power parameters.\"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    G = np.dot(X, Y.T)\n",
    "    return (G + c)**p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Plot the RMSE for various regularization parameters and kernels, using independent subsets of data for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def goodness_of_fit(kers, lams, labels, ti):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.axes([0.12, 0.12, 0.67, 0.8])\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Split into training and testing sets.\n",
    "    ii = np.random.permutation(X.shape[0])\n",
    "    X1 = X[ii[0:2000], :]\n",
    "    y1 = y[ii[0:2000]]\n",
    "    X2 = X[ii[2000:], :]\n",
    "    y2 = y[ii[2000:]]\n",
    "    \n",
    "    # Sweep out a range of kernels.\n",
    "    for j,ker in enumerate(kers):\n",
    "        K1 = ker(X1)\n",
    "        S, B = np.linalg.eigh(K1)\n",
    "        Bty = np.dot(B.T, y1)\n",
    "        K2 = ker(X2, Y=X1)\n",
    "        \n",
    "        # Calculate the RMSE for models with different\n",
    "        # degrees of regularization.\n",
    "        rmse = []\n",
    "        for lam in lams:\n",
    "            alpha_hat = np.dot(np.dot(B, np.diag(S/(S**2 + lam))), Bty)\n",
    "            yhat = np.dot(K2, alpha_hat)\n",
    "            e = np.sqrt(np.mean((y2 - yhat)**2))\n",
    "            rmse.append(e)\n",
    "        plt.plot(lams, rmse, \"-\", label=labels[j])\n",
    "\n",
    "    plt.title(ti)\n",
    "    ha, lb = plt.gca().get_legend_handles_labels()\n",
    "    leg = plt.figlegend(ha, lb, loc=\"center right\")\n",
    "    leg.draw_frame(False)\n",
    "    leg.set_title(\"Kernel scale\")\n",
    "    plt.xlabel(\"Regularization\", size=15)\n",
    "    plt.ylabel(\"RMSE\", size=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "To illustrate the fitted models, plot the fitted values for females and males, using the given kernel and regularization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_fit(ker, lam):\n",
    "\n",
    "    ii = np.random.permutation(X.shape[0])\n",
    "    X1 = X[ii[0:2000], :] # for speed\n",
    "    y1 = y[ii[0:2000]]\n",
    "    \n",
    "    K = ker(X1)\n",
    "    S, B = np.linalg.eigh(K)\n",
    "    alpha_hat = np.dot(np.dot(B, np.diag(S/(S**2 + lam))), np.dot(B.T, y1))\n",
    "\n",
    "    females = np.flatnonzero(X1[:, 0] > 0)\n",
    "    males = np.flatnonzero(X1[:, 0] < 0)\n",
    "\n",
    "    ages = np.linspace(18, 80, 50)\n",
    "    ages_std = (ages - xmn[1]) / xsd[1]\n",
    "    Xp = np.zeros_like(X[0:100, :])\n",
    "    Xp[0:50, 0] = X1[females[0], 0]\n",
    "    Xp[50:, 0] = X1[males[0], 0]\n",
    "    Xp[0:50, 1] = ages_std\n",
    "    Xp[50:, 1] = ages_std\n",
    "\n",
    "    Kp = ker(X1, Y=Xp)\n",
    "    yhat = np.dot(Kp.T, alpha_hat)\n",
    "    yhat = ymn + ysd * yhat\n",
    "\n",
    "    plt.clf()\n",
    "    plt.axes([0.12, 0.12, 0.7, 0.8])\n",
    "    plt.grid(True)\n",
    "    plt.plot(ages, yhat[0:50], \"-\", color=\"purple\", label=\"Female\")\n",
    "    plt.plot(ages, yhat[50:100], \"-\", color=\"orange\", label=\"Male\")\n",
    "    ha, lb = plt.gca().get_legend_handles_labels()\n",
    "    leg = plt.figlegend(ha, lb, loc=\"center right\")\n",
    "    leg.draw_frame(False)\n",
    "    plt.title(\"regularization=%.2f\" % lam)\n",
    "    plt.xlabel(\"Age\", size=15)\n",
    "    plt.ylabel(\"SBP\", size=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Consider goodness of fit for KRR using squared exponential kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [0.5, 1, 2, 4, 8]\n",
    "lams = [0.5, 1, 2, 3, 5, 10, 20]\n",
    "\n",
    "kers = [lambda X, scale=scale, Y=None: ker_sqexp(X, scale=scale, Y=Y) for scale in scales]\n",
    "labels = [\"scale=%.1f\" % x for x in scales]\n",
    "\n",
    "goodness_of_fit(kers, lams, labels, \"Squared exponential kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Consider goodness of fit for KRR using polynomial kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pows = [1, 2, 3, 4]\n",
    "kers = [lambda X, p=p, Y=None: ker_poly(X, c=0.5, p=p, Y=Y) for p in pows]\n",
    "labels = [\"power=%d\" % p for p in pows]\n",
    "goodness_of_fit(kers, [0.01, 0.1, 1, 5, 10], labels, \"Polynomial kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Below we plot estimated conditional mean blood pressure as a function of age and sex, holding all other variables in the model fixed at their mean values.  These fits use squared exponential kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in [4]:\n",
    "    for lam in [1]:\n",
    "        plot_fit(lambda X, scale=scale, Y=None: ker_sqexp(X, scale=scale, Y=Y), lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Here we plot conditional mean blood pressure given age and sex, holding all other variables fixed, but now using polynomial kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [1, 2, 3, 4]:\n",
    "    for lam in [2]:\n",
    "        plot_fit(lambda X, p=p, Y=None: ker_poly(X, p=p, Y=Y), lam)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
